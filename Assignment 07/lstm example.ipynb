{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import os\n",
    "import librosa.feature\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "\n",
    "class GenData(Sequence):\n",
    "    def extract_features(self, file):\n",
    "        wav = librosa.load(file, sr=16E3)\n",
    "        mfcc = librosa.feature.mfcc(*wav, n_mfcc=self.num_mfcc, win_length=320, hop_length=320, n_fft=512, window='hann')\n",
    "        return mfcc\n",
    "\n",
    "    def __init__(self, path, digits, split, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.digits = digits\n",
    "        self.num_classes = len(digits)\n",
    "        self.num_mfcc = 30\n",
    "        self.y = []\n",
    "        self.X = []\n",
    "\n",
    "        test_list = open(os.path.join(path, 'testing_list.txt')).read().split('\\n')\n",
    "        val_list = open(os.path.join(path, 'validation_list.txt')).read().split('\\n')\n",
    "\n",
    "        for idx_digit, str_digit in enumerate(digits):\n",
    "            path_digit = os.path.join(path, str_digit)\n",
    "            files = os.listdir(path_digit)\n",
    "            for f in tqdm(files):\n",
    "                f = str_digit + '/' + f\n",
    "                if split=='test' and f not in test_list:\n",
    "                    continue\n",
    "                elif split=='val' and f not in val_list:\n",
    "                    continue\n",
    "                elif split=='train' and (f in test_list or f in val_list):\n",
    "                    continue\n",
    "\n",
    "                f = os.path.join(path, f)\n",
    "                self.X.append(self.extract_features(f))\n",
    "                self.y.append(np.zeros((self.num_classes,)))\n",
    "                self.y[-1][idx_digit] = 1\n",
    "\n",
    "        self.idx = random.permutation(len(self.y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.X) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        idx_batch = self.idx[item*self.batch_size : (item+1)*self.batch_size]\n",
    "\n",
    "        maxlen = max([self.X[it].shape[1] for it in idx_batch])\n",
    "        X_batch = np.zeros((self.batch_size, maxlen, self.num_mfcc))\n",
    "        y_batch = np.zeros((self.batch_size, self.num_classes))\n",
    "\n",
    "        for it, rand_it in enumerate(idx_batch):\n",
    "            sequence = self.X[rand_it]\n",
    "            X_batch[it, -sequence.shape[1]:, :] = sequence.T\n",
    "            y_batch[it, :] = self.y[rand_it]\n",
    "\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.idx = random.permutation(len(self.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\RWTH Aachen\\\\Audio Processing Using Python\\\\Lab Assignment 07\\\\Training Data Lab Course 7\\\\testing_list.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-a10935cf9898>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mdigits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'five'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'six'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'seven'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'eight'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mpath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'D:\\\\RWTH Aachen\\\\Audio Processing Using Python\\\\Lab Assignment 07\\\\Training Data Lab Course 7\\\\'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mtrain_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGenData\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msplit\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'train'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mdigits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdigits\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mval_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGenData\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msplit\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mdigits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdigits\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-3-f9fc91351612>\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, path, digits, split, batch_size)\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m         \u001B[0mtest_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'testing_list.txt'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m         \u001B[0mval_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'validation_list.txt'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:\\\\RWTH Aachen\\\\Audio Processing Using Python\\\\Lab Assignment 07\\\\Training Data Lab Course 7\\\\testing_list.txt'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "digits = ['five', 'six', 'seven', 'eight']\n",
    "path = 'D:\\\\RWTH Aachen\\\\Audio Processing Using Python\\\\Lab Assignment 07\\\\Training Data Lab Course 7\\\\'\n",
    "train_data = GenData(path, split='train', batch_size=batch_size,  digits=digits)\n",
    "val_data = GenData(path, split='val', batch_size=batch_size,  digits=digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x0, y0 = train_data.__getitem__(0)\n",
    "print(x0.shape)\n",
    "print(y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization, InputLayer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer((None, train_data.num_mfcc)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='linear'))\n",
    "model.add(LSTM(32,activation='tanh', dropout=0.05,  return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32,activation='tanh', dropout=0.05,  return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LSTM(32,activation='tanh', dropout=0.05, return_sequences=False))\n",
    "\n",
    "model.add(Dense(train_data.num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "opt = Adam(learning_rate=0.001)\n",
    "loss = CategoricalCrossentropy()\n",
    "acc = CategoricalAccuracy()\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history =  model.fit(train_data, validation_data=val_data, epochs=10)\n",
    "%matplotlib qt\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data = GenData(path, split='test', batch_size=1, digits=digits)\n",
    "acc_test = model.evaluate(test_data)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "input = Input((None, train_data.num_mfcc))\n",
    "norm = BatchNormalization()(input)\n",
    "x1 = Dense(32, activation='linear')(norm)\n",
    "\n",
    "x = LSTM(32, dropout=0.05, return_sequences=True)(x1)\n",
    "x = BatchNormalization()(x)\n",
    "delta = LSTM(32, dropout=0.05, return_sequences=True)(x)\n",
    "\n",
    "s = Add()([delta, x1])\n",
    "x = BatchNormalization()(s)\n",
    "x = LSTM(32, dropout=0.05, return_sequences=False)(x)\n",
    "output = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "resnet = Model(inputs=input, outputs=output)\n",
    "resnet.compile(optimizer=opt, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet.fit(train_data, epochs=10, validation_data=val_data)\n",
    "resnet.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submodel = Model(inputs=input, outputs=[delta, s])\n",
    "submodel.compile(optimizer=opt, loss=loss, metrics=[acc])\n",
    "x0, y0 = test_data.__getitem__(0)\n",
    "delta_out, s_out = submodel.predict(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(delta_out[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from shutil import rmtree\n",
    "logdir = 'logs'\n",
    "if os.path.isdir(logdir):\n",
    "    rmtree(logdir)\n",
    "os.mkdir(logdir)\n",
    "tensorboard = TensorBoard(log_dir=logdir, histogram_freq=0, profile_batch=0)\n",
    "\n",
    "# resnet.fit(train_data, validation_data=val_data, epochs=100, callbacks=[early_stopping, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(os.path.isdir(logdir))\n",
    "print(logdir)\n",
    "rmtree(logdir)\n",
    "print(os.path.isdir(logdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from kerastuner import HyperParameters\n",
    "\n",
    "def model_builder(hp: HyperParameters):\n",
    "    num_blocks = hp.Int('blocks', min_value=1, max_value=3)\n",
    "    num_units = hp.Choice('units', values=[16, 32, 48])\n",
    "    dropout = hp.Float('dropout', min_value=0, max_value=0.3, step=0.1)\n",
    "    with_skips = hp.Boolean('skips')\n",
    "\n",
    "    input = Input((None, train_data.num_mfcc))\n",
    "    norm = BatchNormalization()(input)\n",
    "    x1 = Dense(num_units, activation='linear')(norm)\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        x = LSTM(num_units, dropout=dropout, return_sequences=True)(x1)\n",
    "        x = BatchNormalization()(x)\n",
    "        delta = LSTM(num_units, dropout=dropout, return_sequences=True)(x)\n",
    "        if with_skips:\n",
    "            s = Add()([delta, x1])\n",
    "        else:\n",
    "            s = delta\n",
    "        x1 = BatchNormalization()(s)\n",
    "\n",
    "    x = LSTM(num_units, dropout=dropout, return_sequences=False)(x1)\n",
    "    output = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=[acc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data.batch_size = 32\n",
    "val_data.batch_size = 32\n",
    "from kerastuner.tuners import Hyperband\n",
    "\n",
    "tuner = Hyperband(model_builder,\n",
    "                  objective='val_categorical_accuracy',\n",
    "                  factor=4,\n",
    "                  directory='tuner_checkpoints',\n",
    "                  project_name='hello_tuner',\n",
    "                  max_epochs=20,\n",
    "                  overwrite=True\n",
    "                  )\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5),\n",
    "    TensorBoard(log_dir=logdir, histogram_freq=0, profile_batch=0)\n",
    "]\n",
    "tuner.search(train_data, validation_data=val_data, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(train_data, validation_data=val_data, epochs=50, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "model.evaluate(test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}